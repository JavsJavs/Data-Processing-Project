{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo para Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import udf, size, col\n",
    "from pyspark.sql.types import (IntegerType, StringType, \n",
    "                               TimestampType, StructType,\n",
    "                               StructField, ArrayType,\n",
    "                               TimestampType)\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StopWordsRemover, RegexTokenizer, \\\n",
    "        CountVectorizer, OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "#conf.set(\"spark.executor.extraClassPath\",  os.path.join(os.getcwd(), 'extras/sqlite-jdbc-3.34.0.jar'))\n",
    "#conf.set(\"spark.driver.extraClassPath\", os.path.join(os.getcwd(), 'extras/sqlite-jdbc-3.34.0.jar'))\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"TwitterStreamApp\", conf=conf)\n",
    "\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "|sentiment|        id|                date|    flag|           user|           transtext|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "|        0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|        0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|        0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|        0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|        0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|        0|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|        0|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|        0|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|        0|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|        0|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|        0|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|        0|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|        0|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|        0|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|        0|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|        0|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|        0|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|        0|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "|        0|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|        0|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#url = 'jdbc:sqlite:' + os.path.join(os.getcwd(), 'database.sqlite')\n",
    "\n",
    "# Importación de los datos de entrenamiento\n",
    "\n",
    "schema = StructType([StructField(\"sentiment\", StringType()),\n",
    "                   StructField(\"id\", StringType()),\n",
    "                   StructField(\"date\", StringType()),\n",
    "                   StructField(\"flag\", StringType()),\n",
    "                   StructField(\"user\", StringType()),\n",
    "                   StructField(\"transtext\", StringType())\n",
    "                  ])\n",
    "\n",
    "\n",
    "\n",
    "df = spark.read.format('csv').schema(schema).load('datasets/tweets_clean.csv')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|sentiment| count|\n",
      "+---------+------+\n",
      "|        0|800000|\n",
      "|        4|800000|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"sentiment\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .distinct() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 1584015\n",
      "Test Dataset Count: 15985\n"
     ]
    }
   ],
   "source": [
    "# División de los datos para entrenamiento y tests\n",
    "\n",
    "(trainingData, testData) = df.randomSplit([0.99, 0.01], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|sentiment|        id|                date|    flag|           user|           transtext|               words|                  tf|            features|label|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|        0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|[@switchfoot, htt...|(65536,[12429,164...|(65536,[12429,164...|  1.0|\n",
      "|        0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|[is, upset, that,...|(65536,[1981,3085...|(65536,[1981,3085...|  1.0|\n",
      "|        0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|[@kenichan, i, di...|(65536,[2888,3924...|(65536,[2888,3924...|  1.0|\n",
      "|        0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|[my, whole, body,...|(65536,[1880,9243...|(65536,[1880,9243...|  1.0|\n",
      "|        0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|[@nationwideclass...|(65536,[1968,3434...|(65536,[1968,3434...|  1.0|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creación de un PipelinedModel\n",
    "my_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"@\"]\n",
    "tokenizer = Tokenizer(inputCol=\"transtext\", outputCol=\"words\")\n",
    "#stopwords = StopWordsRemover(inputCol=\"words\", outputCol='tokens').setStopWords(my_stopwords)\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(trainingData)\n",
    "train_df = pipelineFit.transform(trainingData)\n",
    "val_df = pipelineFit.transform(testData)\n",
    "train_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión logística para casificar los tweets\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0| 8149|\n",
      "|       1.0| 7836|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"prediction\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .distinct() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545616226114139"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación de los resultados\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup de los modelos\n",
    "\n",
    "pipelineFit.save('models/final_idf.model')\n",
    "lrModel.save('models/final_lr.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
