{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import traceback\n",
    "sc = pyspark.SparkContext(appName=\"TwitterStreamApp\")\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export JAVA_HOME='/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "!export PATH=$JAVA_HOME/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_tags_count(new_values, total_sum):\n",
    "    return sum(new_values) + (total_sum or 0)\n",
    "def get_sql_context_instance(spark_context):\n",
    "    if ('sqlContextSingletonInstance' not in globals()):\n",
    "        globals()['sqlContextSingletonInstance'] = SQLContext(spark_context)\n",
    "    return globals()['sqlContextSingletonInstance']\n",
    "def process_rdd(time, rdd):\n",
    "    print(\"----------- %s -----------\" % str(time))\n",
    "    try:\n",
    "        # obtén el contexto spark sql singleton desde el contexto actual\n",
    "        print(\"juan\")\n",
    "        sql_context = get_sql_context_instance(rdd.context)\n",
    "        # convierte el RDD a Row RDD\n",
    "        print(\"chu\")\n",
    "        print(rdd.collect())\n",
    "        row_rdd = rdd.map(lambda w: Row(hashtag=w[0], hashtag_count=w[1]))\n",
    "        # crea un DF desde el Row RDD\n",
    "        print(\"zri\")\n",
    "        hashtags_df = sql_context.createDataFrame(row_rdd)\n",
    "        # Registra el marco de data como tabla\n",
    "        print(\"for\")\n",
    "        hashtags_df.registerTempTable(\"hashtags\")\n",
    "        # obtén los 10 mejores hashtags de la tabla utilizando SQL e imprímelos\n",
    "        print(\"fai\")\n",
    "        hashtag_counts_df = sql_context.sql(\"select hashtag, hashtag_count from hashtags order by hashtag_count desc limit 10\")\n",
    "        print(\"sis\")\n",
    "        hashtag_counts_df.show()\n",
    "        # llama a este método para preparar los 10 mejores hashtags DF y envíalos\n",
    "        #print(\"seve\")\n",
    "        #send_df_to_dashboard(hashtag_counts_df)\n",
    "    except Exception as ex:\n",
    "        traceback.print_exception(type(ex), ex, ex.__traceback__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row,SQLContext\n",
    "import sys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAAAAAA\n",
      "EEEEEEEEEEEEEEEEEE\n",
      "----------- 2021-05-13 22:01:28 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:30 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:32 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:34 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:36 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:38 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:40 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:42 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:44 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:46 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:48 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:50 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:52 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:54 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:56 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:01:58 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:00 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:02 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:04 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:06 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:08 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:10 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:12 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:14 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:16 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:18 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:20 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:22 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:24 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:26 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:28 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:30 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:32 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:34 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:36 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:38 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:40 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:42 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:44 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:46 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:48 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:50 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:52 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:54 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:56 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:02:58 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:00 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:02 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:04 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:06 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:08 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:10 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:12 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:14 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:16 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:18 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:20 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:22 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:24 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:26 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:28 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:30 -----------\n",
      "juan\n",
      "chu\n",
      "[]\n",
      "zri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-15-adc59a733fc0>\", line 19, in process_rdd\n",
      "    hashtags_df = sql_context.createDataFrame(row_rdd)\n",
      "  File \"/opt/spark/python/pyspark/sql/context.py\", line 321, in createDataFrame\n",
      "    return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 605, in createDataFrame\n",
      "    return self._create_dataframe(data, schema, samplingRatio, verifySchema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 628, in _create_dataframe\n",
      "    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 425, in _createFromRDD\n",
      "    struct = self._inferSchema(rdd, samplingRatio, names=schema)\n",
      "  File \"/opt/spark/python/pyspark/sql/session.py\", line 396, in _inferSchema\n",
      "    first = rdd.first()\n",
      "  File \"/opt/spark/python/pyspark/rdd.py\", line 1467, in first\n",
      "    raise ValueError(\"RDD is empty\")\n",
      "ValueError: RDD is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:03:32 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:34 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:36 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:38 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:40 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:42 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:44 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:46 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:48 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:50 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:52 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:54 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:56 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:03:58 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:00 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:02 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:04 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:06 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:08 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:10 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:12 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:14 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:16 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:18 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:20 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:22 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:24 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:26 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:28 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:30 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:32 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:34 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:36 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:38 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:40 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:42 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:44 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:46 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:48 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:50 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:04:52 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:54 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:56 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:04:58 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:00 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:02 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:04 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:06 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:08 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:10 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:12 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:14 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:16 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:18 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:20 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:22 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:24 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:26 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:28 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:30 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:32 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:34 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:36 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:38 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:40 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:42 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:44 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:46 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:48 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:50 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:52 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:54 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:56 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:05:58 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:06:00 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:06:02 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:06:04 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:06:06 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:06:08 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n",
      "----------- 2021-05-13 22:06:10 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2021-05-13 22:06:12 -----------\n",
      "juan\n",
      "chu\n",
      "[('#Twitch', 1)]\n",
      "zri\n",
      "for\n",
      "fai\n",
      "sis\n",
      "+-------+-------------+\n",
      "|hashtag|hashtag_count|\n",
      "+-------+-------------+\n",
      "|#Twitch|            1|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fab73fabf04a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# espera que la transmisión termine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/streaming/context.py\u001b[0m in \u001b[0;36mawaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTermination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mawaitTerminationOrTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# crea un contexto spark con la configuración anterior\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "# crea el Contexto Streaming desde el contexto spark visto arriba con intervalo de 2 segundos\n",
    "ssc = StreamingContext(sc, 2)\n",
    "# establece un punto de control para permitir la recuperación de RDD\n",
    "ssc.checkpoint(\"checkpoint_TwitterApp\")\n",
    "# lee data del puerto 9009\n",
    "dataStream = ssc.socketTextStream(\"localhost\",8008)\n",
    "# divide cada Tweet en palabras\n",
    "words = dataStream.flatMap(lambda line: line.split(\" \"))\n",
    "print(\"AAAAAAAAAAAAAAAAA\")\n",
    "# filtra las palabras para obtener solo hashtags, luego mapea cada hashtag para que sea un par de (hashtag,1)\n",
    "hashtags = words.filter(lambda w: '#' in w).map(lambda x: (x, 1))\n",
    "# agrega la cuenta de cada hashtag a su última cuenta\n",
    "tags_totals = hashtags.updateStateByKey(aggregate_tags_count)\n",
    "print(\"EEEEEEEEEEEEEEEEEE\")\n",
    "words.saveAsTextFiles('oal')\n",
    "# procesa cada RDD generado en cada intervalo\n",
    "tags_totals.foreachRDD(process_rdd)\n",
    "mySsc = ssc\n",
    "# comienza la computación de streaming\n",
    "ssc.start()\n",
    "# espera que la transmisión termine\n",
    "ssc.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
