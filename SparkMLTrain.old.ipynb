{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import udf, size, col\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import (IntegerType, StringType, \n",
    "                               TimestampType, StructType,\n",
    "                               StructField, ArrayType,\n",
    "                               TimestampType)\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "conf.set(\"spark.executor.extraClassPath\",  os.path.join(os.getcwd(), 'extras/sqlite-jdbc-3.34.0.jar'))\n",
    "conf.set(\"spark.driver.extraClassPath\", os.path.join(os.getcwd(), 'extras/sqlite-jdbc-3.34.0.jar'))\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"TwitterStreamApp\", conf=conf)\n",
    "\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "|sentiment|        id|                date|    flag|           user|           transtext|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "|        0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|        0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|        0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|        0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|        0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|        0|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|        0|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|        0|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|        0|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|        0|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|        0|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|        0|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|        0|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|        0|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|        0|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|        0|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|        0|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|        0|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "|        0|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|        0|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'jdbc:sqlite:' + os.path.join(os.getcwd(), 'database.sqlite')\n",
    "\n",
    "#df = spark.read.jdbc(url, 'Tweet')\n",
    "#targetUDF = udf(lambda x:int(x), IntegerType())\n",
    "\n",
    "schema = StructType([StructField(\"sentiment\", StringType()),\n",
    "                   StructField(\"id\", StringType()),\n",
    "                   StructField(\"date\", StringType()),\n",
    "                   StructField(\"flag\", StringType()),\n",
    "                   StructField(\"user\", StringType()),\n",
    "                   StructField(\"transtext\", StringType())\n",
    "                  ])\n",
    "\n",
    "\n",
    "\n",
    "df = spark.read.format('csv').schema(schema).load('datasets/tweets_clean.csv')\n",
    "#df2 = df.withColumn(\"sentiment\", targetUDF(df[\"target\"]))\n",
    "#map_sentiment = udf(lambda x : \n",
    "  #                  float(x.replace('Positive', '0').replace('Neutral', '1').replace('Negative', '2')))\n",
    "#df = df.withColumn('sentiment', map_sentiment('sentiment')).select('transtext', 'sentiment')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|sentiment| count|\n",
      "+---------+------+\n",
      "|        0|800000|\n",
      "|        4|800000|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"sentiment\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .distinct() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeRegex(tokens: list) -> list:\n",
    "    \"\"\"\n",
    "    Removes hashtags, call outs and web addresses from tokens.\n",
    "    \"\"\"\n",
    "    expr    = '(@[A-Za-z0-a9_]+)|(#[A-Za-z0-9_]+)|'+\\\n",
    "              '(https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+)'\n",
    "        \n",
    "    regex   = re.compile(expr)\n",
    "\n",
    "    cleaned = [t for t in tokens if not(regex.search(t)) if len(t) > 0]\n",
    "\n",
    "    return list(filter(None, cleaned))\n",
    "\n",
    "def normalize(tokens : list) -> list:\n",
    "    \"\"\"\n",
    "    Removes non-english characters and returns lower case versions of words.\n",
    "    \"\"\"\n",
    "    subbed   = [re.sub(\"[^a-zA-Z]+\", \"\", s).lower() for s in tokens]\n",
    "    \n",
    "    filtered = filter(None, subbed)\n",
    "    \n",
    "    return list(filtered)\n",
    "\n",
    "\n",
    "normalizeUDF = udf(normalize, ArrayType(StringType()))\n",
    "\n",
    "removeWEBUDF = udf(removeRegex, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol  = \"transtext\",\n",
    "                      outputCol = \"token\")\n",
    "\n",
    "df3 = tokenizer.transform(df)\n",
    "# remove hashtags, call outs and web addresses\n",
    "df4 = df3.withColumn(\"tokens_re\", removeWEBUDF(df3[\"token\"]))\n",
    "\n",
    "# remove non english characters\n",
    "df4 = df4.withColumn(\"tokens_clean\", normalizeUDF(df4[\"tokens_re\"]))\n",
    "\n",
    "# rename columns\n",
    "df5 = df4.drop(\"token\",\"tokens_re\")\n",
    "df5 = df5.withColumnRenamed(\"tokens_clean\", \"tokens\")\\\n",
    "\n",
    "# remove tweets where the tokens array is empty, i.e. where it was just\n",
    "# a hashtag, callout, numbers, web adress etc.\n",
    "df6 = df5.where(size(col(\"tokens\")) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 1119936\n",
      "Test Dataset Count: 480064\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set seed for reproducibility\n",
    "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "#evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|sentiment|        id|                date|    flag|           user|           transtext|               words|                  tf|            features|label|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|        0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|[@switchfoot, htt...|(65536,[12429,164...|(65536,[12429,164...|  0.0|\n",
      "|        0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|[is, upset, that,...|(65536,[1981,3085...|(65536,[1981,3085...|  0.0|\n",
      "|        0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|[@kenichan, i, di...|(65536,[2888,3924...|(65536,[2888,3924...|  0.0|\n",
      "|        0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|[@nationwideclass...|(65536,[1968,3434...|(65536,[1968,3434...|  0.0|\n",
      "|        0|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|[@kwesidei, not, ...|(65536,[15171,175...|(65536,[15171,175...|  0.0|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"transtext\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(trainingData)\n",
    "train_df = pipelineFit.transform(trainingData)\n",
    "val_df = pipelineFit.transform(testData)\n",
    "train_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8458981424549241"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit.save('models/final_idf.model')\n",
    "lrModel.save('models/final_lr.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|sentiment|        id|                date|    flag|           user|           transtext|               words|                  tf|            features|label|       rawPrediction|         probability|prediction|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|        0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|[my, whole, body,...|(65536,[1880,9243...|(65536,[1880,9243...|  0.0|[1.73435231498434...|[0.84996828283741...|       0.0|\n",
      "|        0|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|[spring, break, i...|(65536,[5284,3026...|(65536,[5284,3026...|  0.0|[-0.4149626478568...|[0.39772277038595...|       1.0|\n",
      "|        0|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|[i, just, re-pier...|(65536,[19036,316...|(65536,[19036,316...|  0.0|[-1.1979919131526...|[0.23183263659581...|       1.0|\n",
      "|        0|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|[@smarrison, i, w...|(65536,[8225,1631...|(65536,[8225,1631...|  0.0|[3.03846879197099...|[0.95428207242903...|       0.0|\n",
      "|        0|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|[@iamjazzyfizzle,...|(65536,[835,18354...|(65536,[835,18354...|  0.0|[4.59073288375670...|[0.98995647554189...|       0.0|\n",
      "|        0|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|[@fakerpattypattz...|(65536,[18184,183...|(65536,[18184,183...|  0.0|[0.73297965312474...|[0.67545879607346...|       0.0|\n",
      "|        0|1467813985|Mon Apr 06 22:20:...|NO_QUERY|         quanvu|@alydesigns i was...|[@alydesigns, i, ...|(65536,[8225,1122...|(65536,[8225,1122...|  0.0|[0.39378013353374...|[0.59719235732471...|       0.0|\n",
      "|        0|1467814438|Mon Apr 06 22:20:...|NO_QUERY|  ChicagoCubbie|I hate when I hav...|[i, hate, when, i...|(65536,[7173,1223...|(65536,[7173,1223...|  0.0|[2.33378090820708...|[0.91163638404826...|       0.0|\n",
      "|        0|1467815753|Mon Apr 06 22:21:...|NO_QUERY|BaptisteTheFool|Meh... Almost Lov...|[meh..., almost, ...|(65536,[6261,1541...|(65536,[6261,1541...|  0.0|[1.24727968681412...|[0.77682860674347...|       0.0|\n",
      "|        0|1467816665|Mon Apr 06 22:21:...|NO_QUERY|           jsoo|@HumpNinja I cry ...|[@humpninja, i, c...|(65536,[5827,8449...|(65536,[5827,8449...|  0.0|[1.71159446485109...|[0.84704297929784...|       0.0|\n",
      "|        0|1467816749|Mon Apr 06 22:21:...|NO_QUERY| scarletletterm|ok I'm sick and s...|[ok, i'm, sick, a...|(65536,[1198,1589...|(65536,[1198,1589...|  0.0|[5.02173636877088...|[0.99345011507583...|       0.0|\n",
      "|        0|1467817374|Mon Apr 06 22:21:...|NO_QUERY|        ajaxpro|@MissXu sorry! be...|[@missxu, sorry!,...|(65536,[308,19247...|(65536,[308,19247...|  0.0|[0.02697531826973...|[0.50674342065822...|       0.0|\n",
      "|        0|1467817502|Mon Apr 06 22:21:...|NO_QUERY|        Tmttq86|@fleurylis I don'...|[@fleurylis, i, d...|(65536,[7221,9243...|(65536,[7221,9243...|  0.0|[4.57031084832366...|[0.98975138132293...|       0.0|\n",
      "|        0|1467818020|Mon Apr 06 22:21:...|NO_QUERY|     itsanimesh|really don't feel...|[really, don't, f...|(65536,[3642,6640...|(65536,[3642,6640...|  0.0|[2.67886382877474...|[0.93576786627251...|       0.0|\n",
      "|        0|1467818481|Mon Apr 06 22:21:...|NO_QUERY|      lionslamb|He's the reason f...|[he's, the, reaso...|(65536,[1714,1880...|(65536,[1714,1880...|  0.0|[0.21402355279160...|[0.55330257817594...|       0.0|\n",
      "|        0|1467820206|Mon Apr 06 22:22:...|NO_QUERY|       peacoats|is strangely sad ...|[is, strangely, s...|(65536,[9564,1539...|(65536,[9564,1539...|  0.0|[2.05469900161100...|[0.88642156627745...|       0.0|\n",
      "|        0|1467821085|Mon Apr 06 22:22:...|NO_QUERY| crzy_cdn_bulas|our duck and chic...|[our, duck, and, ...|(65536,[1257,4629...|(65536,[1257,4629...|  0.0|[0.63600861425621...|[0.65385064595232...|       0.0|\n",
      "|        0|1467822519|Mon Apr 06 22:22:...|NO_QUERY|        gzacher|Ugh....92 degrees...|[ugh....92, degre...|(65536,[24651,291...|(65536,[24651,291...|  0.0|[0.48547771836306...|[0.61904052121824...|       0.0|\n",
      "|        0|1467822522|Mon Apr 06 22:22:...|NO_QUERY|         Jenn_L|Where did u move ...|[where, did, u, m...|(65536,[2306,5537...|(65536,[2306,5537...|  0.0|[-0.9353424732542...|[0.28184210060907...|       1.0|\n",
      "|        0|1467823437|Mon Apr 06 22:23:...|NO_QUERY|          xpika|The Life is cool....|[the, life, is, c...|(65536,[23685,250...|(65536,[23685,250...|  0.0|[0.23867953481159...|[0.55938821576602...|       0.0|\n",
      "+---------+----------+--------------------+--------+---------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"transtext\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "## stop words\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",\"@\"]\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "\n",
    "## bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "## convert string labels to indexes\n",
    "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, seed=100)\n",
    "\n",
    "## build the pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx, rf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokens from tweets\n",
    "tk = Tokenizer(inputCol= \"transtext\", outputCol = \"tokens2\")\n",
    "\n",
    "# create term frequencies for each of the tokens\n",
    "sw  = StopWordsRemover(inputCol=\"tokens2\", outputCol=\"filtered\")\n",
    "#tf1 = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1e5)\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
    "\n",
    "# create tf-idf for each of the tokens\n",
    "#idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2.0)\n",
    "\n",
    "# create basic logistic regression model\n",
    "#lr = LogisticRegression(maxIter=20)\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, seed=100)\n",
    "\n",
    "# create entire pipeline\n",
    "pipeline = Pipeline(stages=[tk, sw, countVectors, label_stringIdx, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.5045871559633027\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "predictions1 = model.transform(testData)\n",
    "\n",
    "# get the performance on the test set\n",
    "score1 = evaluator.evaluate(predictions1)\n",
    "\n",
    "print(\"AUC SCORE: {}\".format(score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.5045871559633027\n"
     ]
    }
   ],
   "source": [
    "predictedAndLabels = predictions1.select([\"prediction\",\"sentiment\"])\\\n",
    "                                 .rdd.map(lambda r : (float(r[0]), float(r[1])))\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "metrics = MulticlassMetrics(predictedAndLabels)\n",
    "\n",
    "print(\"Test Set Accuracy: {}\".format(metrics.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|       0.0|236162|\n",
      "|       1.0|243902|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"prediction\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .distinct() \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/sentiment3.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+---------+----------------------------------------+-----+----------+\n",
      "|                               transtext|sentiment|                             probability|label|prediction|\n",
      "+----------------------------------------+---------+----------------------------------------+-----+----------+\n",
      "|RT @Schrodingergata: Look that I thin...|      0.0|[0.612140336685387,0.2414551091608311...|  0.0|       0.0|\n",
      "|RT @Schrodingergata: Look that I thin...|      0.0|[0.612140336685387,0.2414551091608311...|  0.0|       0.0|\n",
      "|RT @Sanchezrm_: How proud of Real Mad...|      0.0|[0.5899025841931839,0.228770687339982...|  0.0|       0.0|\n",
      "|Go crack !!!!!  Congratulations @Turm...|      0.0|[0.5870870398050767,0.273805963827021...|  0.0|       0.0|\n",
      "|RT @ECobeNefactor: All for concerted ...|      1.0|[0.5677113201471531,0.256731466657365...|  1.0|       0.0|\n",
      "|@Pecobo_Foto @el_pais Dream daily wit...|      0.0|[0.5672565683512226,0.272343966791321...|  0.0|       0.0|\n",
      "|B.Boys until death!  Productive ma√±an...|      2.0|[0.5618243335051732,0.277500457871824...|  2.0|       0.0|\n",
      "|RT @abalosmeco: We are going to promo...|      0.0|[0.5577209993657303,0.228020212728715...|  0.0|       0.0|\n",
      "|How to undermine, despise ... go pres...|      2.0|[0.554855223761502,0.3020898295980432...|  2.0|       0.0|\n",
      "|@Avila_Turismo @avila_cyl Discover th...|      1.0|[0.552890793010311,0.2705240892703345...|  1.0|       0.0|\n",
      "|@ MAHE_59 I prefer to die of heat to ...|      2.0|[0.5521678233853469,0.282172975761499...|  2.0|       0.0|\n",
      "|RT @sextevenloveyou: Well, we already...|      0.0|[0.5429649300271852,0.265566782079704...|  0.0|       0.0|\n",
      "|RT @ AMAPOLLABANCA11: @unionttps @miq...|      0.0|[0.5395754227185533,0.309606277284342...|  0.0|       0.0|\n",
      "|RT @ Zapatista72: In Madrid, Ayuso ha...|      0.0|[0.534449167684955,0.2314602755867700...|  0.0|       0.0|\n",
      "|RT @fptimimadrid: #taxiiconodemadrid ...|      1.0|[0.5327129552352224,0.236021402966610...|  1.0|       0.0|\n",
      "|RT @MoonWorldr: #queenforkids returns...|      0.0|[0.5322581696287741,0.306280402542762...|  0.0|       0.0|\n",
      "|@ User3432 @ucammurciacf @terrassafc ...|      0.0|[0.5320985004354626,0.301077326936260...|  0.0|       0.0|\n",
      "|130. Here there are more gray hair fo...|      0.0|[0.5319585435762374,0.300168144588386...|  0.0|       0.0|\n",
      "|The world's media speak of the histor...|      1.0|[0.5296966694953967,0.263556959289322...|  1.0|       0.0|\n",
      "|Roca King: 'I am happy to have been a...|      0.0|[0.5278144362661782,0.313544207822758...|  0.0|       0.0|\n",
      "|RT @pijusmagnificvs: Chorpecha that f...|      0.0|[0.5256202850824546,0.313875911518831...|  0.0|       0.0|\n",
      "|               Fucking to Madrid always |      1.0|[0.5243703922251882,0.323509760625627...|  1.0|       0.0|\n",
      "|RT @Savi_Mosby: Being the Valladolid ...|      0.0|[0.5232566193152778,0.274148770711914...|  0.0|       0.0|\n",
      "|RT @ IsmaelGarcia311: Acogelos in you...|      1.0|[0.5222414833356879,0.314094868350919...|  1.0|       0.0|\n",
      "|Today Atl√©tico is going to win the mo...|      0.0|[0.5220203051391757,0.292054790923473...|  0.0|       0.0|\n",
      "|@Manuj_hidalgo has to be hard. Here t...|      0.0|[0.5196206796009686,0.303691222341703...|  0.0|       0.0|\n",
      "|@Heatherhartisim Mestizo, gypsy by fa...|      0.0|[0.5189920499215982,0.245803138353284...|  0.0|       0.0|\n",
      "|            @HoyPalestina to win votes. |      0.0|[0.5147563689753442,0.330320512674439...|  0.0|       0.0|\n",
      "|@ Nacho991960 @Pod√©s Why are you leav...|      1.0|[0.5142955058840072,0.300023522727479...|  1.0|       0.0|\n",
      "|@Disneyplushelf have a telephone numb...|      0.0|[0.5114418706964468,0.317821509329269...|  0.0|       0.0|\n",
      "|@SSSFORENSE I have my heart stolen .....|      0.0|[0.510818966711477,0.3307266241276208...|  0.0|       0.0|\n",
      "|@ Nidia63 @jucarjim thank you Nidia, ...|      0.0|[0.5107881147857505,0.253000030879116...|  0.0|       0.0|\n",
      "|@Arteenmadrid @danielaquillue I think...|      0.0|[0.5088703928958962,0.324877991326674...|  0.0|       0.0|\n",
      "|RT @GabrielCasazza: The whole world t...|      1.0|[0.5082652428586555,0.311950615545611...|  1.0|       0.0|\n",
      "| @Seovision perfect! Whenever you want. |      0.0|[0.5065380182653562,0.343629694888719...|  0.0|       0.0|\n",
      "|RT @Lavacalloria: @ amapolablanca11 @...|      2.0|[0.5060187723885562,0.339576887863787...|  2.0|       0.0|\n",
      "|Rt @baby_aamy: üìç Madrid ‚ö†Ô∏è  With jus...|      0.0|[0.5056831303352637,0.353530214329983...|  0.0|       0.0|\n",
      "|Approved the remodeling of Ortega and...|      0.0|[0.5055858192160291,0.320715042535302...|  0.0|       0.0|\n",
      "|RT @Nacho_Murgui: Citizenship deserve...|      1.0|[0.5053347476608667,0.297048585116211...|  1.0|       0.0|\n",
      "|RT @HoyPalestina: Thousands of protes...|      0.0|[0.5050499059068215,0.320470165376550...|  0.0|       0.0|\n",
      "|         @alo_oficial luck and for them |      0.0|[0.5049911199827207,0.342099286275825...|  0.0|       0.0|\n",
      "|@Cantogoles especially when your daug...|      1.0|[0.5046282577092718,0.289897106879168...|  1.0|       0.0|\n",
      "|                       It's time to cry |      2.0|[0.5019707721728015,0.309706464895241...|  2.0|       0.0|\n",
      "|RT @TomasFSIE: üì£ ùêÇùêÄùêåùêèùêÄùêçùêÄ ùêÄùêÖ...|      1.0|[0.5002935673424268,0.307478150276364...|  1.0|       0.0|\n",
      "|the UA nor in the top so it is as it ...|      2.0|[0.4958244490424159,0.347168208869626...|  2.0|       0.0|\n",
      "|RT @ftorodelidia: ‚ú≥Ô∏è Anto√±ete was Mad...|      1.0|[0.49480953824451973,0.28394503163156...|  1.0|       0.0|\n",
      "|See how wonderful @Tabernita https://...|      0.0|[0.49040441253006384,0.37547521883154...|  0.0|       0.0|\n",
      "|I as a subscriber of the Barsa, it wo...|      0.0|[0.49037191730111823,0.29771091578138...|  0.0|       0.0|\n",
      "|RT @ErtareSarodr_: The march for the ...|      0.0|[0.4899612282343964,0.303591349991808...|  0.0|       0.0|\n",
      "|RT @ MAMP21: @nicolagciab #cundinamar...|      2.0|[0.48646523968766514,0.34636764027497...|  2.0|       0.0|\n",
      "|RT @Marianofake: 2,000 workers to the...|      0.0|[0.48482180331578234,0.26365897656326...|  0.0|       0.0|\n",
      "|The sequelae of the Covid19; Somethin...|      2.0|[0.48390386260389995,0.36065951663796...|  2.0|       0.0|\n",
      "|@mikemoratinos @ alexchef1979 the pain! |      2.0|[0.4839018367767347,0.367006066882803...|  2.0|       0.0|\n",
      "|  @pescanova_es is really rich !! üòãüòã. |      0.0|[0.4839018367767347,0.367006066882803...|  0.0|       0.0|\n",
      "|                            Haha majee. |      0.0|[0.4839018367767347,0.367006066882803...|  0.0|       0.0|\n",
      "|The most beautiful day of the year üíõ...|      0.0|[0.4821172514015386,0.362861842330079...|  0.0|       0.0|\n",
      "|Just publish a photo in Region of Mur...|      1.0|[0.4815152640860093,0.363702945713106...|  1.0|       0.0|\n",
      "|@KikeDelafuente @Migquintana hahahaha...|      1.0|[0.4789851701100681,0.365972733549470...|  1.0|       0.0|\n",
      "|RT @ Rubio_ATM82: Madrid Castia and R...|      0.0|[0.4786613289450629,0.381690480310874...|  0.0|       0.0|\n",
      "|RT @Jornouk: Madrid chose freedom. ht...|      0.0|[0.47760425642755505,0.38390076287816...|  0.0|       0.0|\n",
      "|         Well, https://t.co/cvaqvauyta. |      0.0|[0.4745235665110442,0.386311514926980...|  0.0|       0.0|\n",
      "|Have you told you the story of when t...|      1.0|[0.4737148592394198,0.247787381810518...|  1.0|       0.0|\n",
      "|And I've taken a piece of cheese from...|      0.0|[0.470654535875136,0.3181414053824453...|  0.0|       0.0|\n",
      "|RT @MARIAPASTORV: Madrid Central redu...|      2.0|[0.46793944340758964,0.29849240549613...|  2.0|       0.0|\n",
      "|I have been updated for more than an ...|      1.0|[0.46699091742438215,0.32714787326667...|  1.0|       0.0|\n",
      "|What disgust should you feel the hobb...|      2.0|[0.46578606475757267,0.28263889713789...|  2.0|       0.0|\n",
      "|@el_floriano in his best Queeee? http...|      0.0|[0.4656474018796557,0.392877955451630...|  0.0|       0.0|\n",
      "|The teacher #Gener üèÜ has been Juanma...|      1.0|[0.46551067266919127,0.27685406876201...|  1.0|       0.0|\n",
      "|do me the favor and return to the cab...|      0.0|[0.462791305730972,0.2843607932042948...|  0.0|       0.0|\n",
      "|@ Luciayya16 @zcritizen @albvillalgua...|      0.0|[0.45970464674141276,0.25461292362455...|  0.0|       0.0|\n",
      "|RT @jordicruzperez: And the bull, who...|      1.0|[0.45636875249380304,0.38882266985617...|  1.0|       0.0|\n",
      "|Just publish a photo in ceramic stadi...|      1.0|[0.4525214305719958,0.409816152651075...|  1.0|       0.0|\n",
      "|Just publish a photo in Blanes - Cost...|      1.0|[0.4525214305719958,0.409816152651075...|  1.0|       0.0|\n",
      "|If you have it is because you've been...|      2.0|[0.4525204686570083,0.288300266667759...|  2.0|       0.0|\n",
      "|I give you an ostia and I get to walk...|      1.0|[0.45143317010720657,0.30034798435165...|  1.0|       0.0|\n",
      "|I flip this thread and I can think of...|      0.0|[0.45036172091829735,0.34723855022167...|  0.0|       0.0|\n",
      "|Just publish a photo in √âcija, Spain ...|      1.0|[0.44785037794041693,0.41632931054581...|  1.0|       0.0|\n",
      "|RT @jc_c_a: The Community of Madrid, ...|      1.0|[0.4471420844022732,0.286619948240181...|  1.0|       0.0|\n",
      "|RT @PetroForthRe_: It looks like 2 tr...|      0.0|[0.4466191165693245,0.326990078192280...|  0.0|       0.0|\n",
      "|Education Counseling Madrid: Keep sta...|      1.0|[0.4409515046379086,0.321841141704108...|  1.0|       0.0|\n",
      "|xq nobody says \"Franco Franco who has...|      2.0|[0.4408761179031528,0.361289365818173...|  2.0|       0.0|\n",
      "|Westin Palace workers unlieved the st...|      0.0|[0.4352764217055495,0.435408512934380...|  0.0|       1.0|\n",
      "|RT @cepasierranorte: The 2021 edition...|      1.0|[0.43480606617170736,0.30788806474992...|  1.0|       0.0|\n",
      "|RT @ SARU07003: Celebrate a league? W...|      0.0|[0.4316492107790678,0.342148895504818...|  0.0|       0.0|\n",
      "|Rt @noAnamresiva: The occupation is n...|      0.0|[0.4265176250478549,0.301727856098126...|  0.0|       0.0|\n",
      "|Apart from the pellet, our child has ...|      1.0|[0.4264082310198647,0.345120610050359...|  1.0|       0.0|\n",
      "|@ Dannywilches14 Moreover, I invested...|      0.0|[0.4250530913333629,0.325885866459199...|  0.0|       0.0|\n",
      "|As if that were not enough, on some r...|      1.0|[0.42233271884765206,0.26811250896706...|  1.0|       0.0|\n",
      "|@Hastakander I do not forget, my chil...|      0.0|[0.4174412978670393,0.277519896581724...|  0.0|       0.0|\n",
      "|@ virgi_m13 @gloriasaavglez made the ...|      2.0|[0.4170053644797221,0.248837646195557...|  2.0|       0.0|\n",
      "|@Espanamoro if you go eniling holders...|      0.0|[0.4160329294660911,0.265969113719290...|  0.0|       0.0|\n",
      "|At the crossroads of this hard path t...|      1.0|[0.4122860849587061,0.256340828340536...|  1.0|       0.0|\n",
      "|@Kromicb I do what I can, thank you s...|      0.0|[0.41124398349205776,0.33807757381015...|  0.0|       0.0|\n",
      "|Telita teams or brands the bitch that...|      2.0|[0.40852231112448495,0.28834841562717...|  2.0|       0.0|\n",
      "|RT @ Carmeniglesia2: Madrid Concentra...|      1.0|[0.40838795640164777,0.30473282583787...|  1.0|       0.0|\n",
      "|@BoloSforo @xlemus You do not have mo...|      2.0|[0.4061084159760853,0.245243650810946...|  2.0|       0.0|\n",
      "|@ yager821 @ striker873 @reinaldodmm ...|      0.0|[0.40262122845356296,0.29333314640015...|  0.0|       0.0|\n",
      "|According to @larazon_es Madrid is ne...|      2.0|[0.39890126932524667,0.27085943173231...|  2.0|       0.0|\n",
      "|@ DanicR1 I do not know I'm going to ...|      0.0|[0.3959116527209529,0.190604062096350...|  0.0|       2.0|\n",
      "|@juanma_rguez translation; They laugh...|      0.0|[0.3946933100096783,0.241347638657183...|  0.0|       0.0|\n",
      "+----------------------------------------+---------+----------------------------------------+-----+----------+\n",
      "only showing top 100 rows\n",
      "\n",
      "Accuracy: 0.513761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(trainingData)\n",
    "predictions = pipelineFit.transform(testData)\n",
    "\n",
    "predictions.select(\"transtext\",\"sentiment\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 100, truncate = 40)\n",
    "#predictions.filter(predictions['prediction'] == 0.0) \\\n",
    "#    .select(\"_c5\",\"_c0\",\"probability\",\"label\",\"prediction\") \\\n",
    "#    .orderBy(\"probability\", ascending=False) \\\n",
    "#    .show(n = 10, truncate = 30)\n",
    "#\n",
    "#predictions.filter(predictions['prediction'] == 1.0) \\\n",
    "#    .select(\"_c5\",\"_c0\",\"probability\",\"label\",\"prediction\") \\\n",
    "#    .orderBy(\"probability\", ascending=False) \\\n",
    "#    .show(n = 10, truncate = 30)\n",
    "#    \n",
    "#predictions.filter(predictions['prediction'] == 2.0) \\\n",
    "#    .select(\"_c5\",\"_c0\",\"probability\",\"label\",\"prediction\") \\\n",
    "#    .orderBy(\"probability\", ascending=False) \\\n",
    "#    .show(n = 10, truncate = 30)    \n",
    "\n",
    "# Evaluate, metricName=[accuracy | f1]default f1 measure\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print(\"Accuracy: %g\" % (evaluator.evaluate(predictions)))\n",
    "\n",
    "# save the trained model for future use\n",
    "pipelineFit.save(\"models/sentiment_4.model\")\n",
    "\n",
    "# PipelineModel.load(\"logreg.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
